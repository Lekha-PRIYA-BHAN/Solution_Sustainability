{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from operator import itemgetter\n",
    "from langchain.schema import format_document\n",
    "\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, HumanMessage, get_buffer_string, BaseMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from pprint import pprint\n",
    "from generate_model_footprint import get_model_footprint, get_prompt\n",
    "from analyze_solution_picture import analyze_picture\n",
    "from generate_recommendations import generate_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_path=\"C:/Users/MANISHGUPTA/kyndryl/github/solution-sustainability/images/architecture2.png\"\n",
    "#components = analyze_picture(image_path)\n",
    "#print(components)\n",
    "#exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Analyzing the provided solution architecture', 'there are several areas where the carbon footprint could potentially be high due to the nature of cloud services being used and the data flow patterns. Here are some of the patterns and scenarios that could contribute to a higher carbon footprint:1. **Data Ingestion and Continuous Streaming**: The architecture shows data being ingested from vehicles through IoT Hub and processed by Azure Stream Analytics. If there is a high volume of data being continuously streamed from numerous vehicles', 'this could lead to significant energy consumption due to the constant processing required.2. **Complex Data Storage Solutions**: The architecture includes Azure Cosmos DB', 'Azure SQL', 'and Azure Synapse Analytics for serving storage. Each of these services is designed to handle large amounts of data', 'and depending on the scale and usage patterns', 'they could consume a lot of energy. Over-provisioning or inefficient use of these services could result in a higher carbon footprint.3. **Frequent Data Transfers**: There are multiple data transfers between services', 'such as from IoT Hub to storage solutions and from storage to presentation layers like web and mobile apps. Frequent data transfers', 'especially if data is not compressed or optimized', 'can lead to increased energy usage.4. **Real-time Analytics**: Azure Stream Analytics is used for real-time data processing. Real-time analytics can be resource-intensive', 'especially when dealing with large datasets or requiring complex computations.5. **Edge Computing**: Azure IoT Edge is used at the service center', 'which suggests that some data processing is being done on-premises. If the edge devices are not optimized for energy efficiency', 'they could contribute to the overall carbon footprint.6. **Augmented Reality**: The use of HoloLens for interaction indicates the presence of augmented reality features. AR can be computationally intensive and', 'depending on the scale of deployment', 'could lead to increased energy consumption.7. **API Management and Integration Services**: The use of API Management suggests that there are numerous integrations with external systems such as insurance companies', 'partners', 'suppliers', 'and service centers. The overhead of managing these integrations and the potential for inefficient data exchange can increase the carbon footprint.8. **Development and Monitoring Services**: Azure DevOps and Azure Monitor are part of the shared services. Continuous integration/continuous deployment (CI/CD) pipelines in Azure DevOps can lead to frequent builds and deployments', 'which consume resources. Additionally', 'extensive monitoring and logging can also result in additional storage and processing requirements.To mitigate the carbon footprint', 'the architecture could be optimized by:- Implementing efficient data processing and storage strategies', 'such as data deduplication', 'compression', 'and caching.- Using autoscaling and demand-based provisioning to ensure that resources are scaled down when not in use.- Employing edge computing effectively to process data locally and reduce the amount of data transferred to the cloud.- Optimizing real-time analytics to process only the necessary data and reduce the computational load.- Regularly reviewing and optimizing the CI/CD pipelines to minimize unnecessary builds and deployments.- Ensuring that all services are configured to be as energy-efficient as possible', \"including the use of energy-efficient hardware where applicable.It's important to note that cloud providers like Microsoft Azure are continuously improving their infrastructure to be more energy-efficient and are investing in renewable energy sources\", 'which can help reduce the carbon footprint of cloud services']\n"
     ]
    }
   ],
   "source": [
    "image_path=\"C:/Users/MANISHGUPTA/kyndryl/github/solution-sustainability/images/architecture.png\"\n",
    "recommendations = generate_recommendations(image_path)\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Analyzing the provided solution architecture',\n",
      " 'there are several areas where the carbon footprint could potentially be high '\n",
      " 'due to the nature of cloud services being used and the data flow patterns. '\n",
      " 'Here are some of the patterns and scenarios that could contribute to a '\n",
      " 'higher carbon footprint:1. **Data Ingestion and Continuous Streaming**: The '\n",
      " 'architecture shows data being ingested from vehicles through IoT Hub and '\n",
      " 'processed by Azure Stream Analytics. If there is a high volume of data being '\n",
      " 'continuously streamed from numerous vehicles',\n",
      " 'this could lead to significant energy consumption due to the constant '\n",
      " 'processing required.2. **Complex Data Storage Solutions**: The architecture '\n",
      " 'includes Azure Cosmos DB',\n",
      " 'Azure SQL',\n",
      " 'and Azure Synapse Analytics for serving storage. Each of these services is '\n",
      " 'designed to handle large amounts of data',\n",
      " 'and depending on the scale and usage patterns',\n",
      " 'they could consume a lot of energy. Over-provisioning or inefficient use of '\n",
      " 'these services could result in a higher carbon footprint.3. **Frequent Data '\n",
      " 'Transfers**: There are multiple data transfers between services',\n",
      " 'such as from IoT Hub to storage solutions and from storage to presentation '\n",
      " 'layers like web and mobile apps. Frequent data transfers',\n",
      " 'especially if data is not compressed or optimized',\n",
      " 'can lead to increased energy usage.4. **Real-time Analytics**: Azure Stream '\n",
      " 'Analytics is used for real-time data processing. Real-time analytics can be '\n",
      " 'resource-intensive',\n",
      " 'especially when dealing with large datasets or requiring complex '\n",
      " 'computations.5. **Edge Computing**: Azure IoT Edge is used at the service '\n",
      " 'center',\n",
      " 'which suggests that some data processing is being done on-premises. If the '\n",
      " 'edge devices are not optimized for energy efficiency',\n",
      " 'they could contribute to the overall carbon footprint.6. **Augmented '\n",
      " 'Reality**: The use of HoloLens for interaction indicates the presence of '\n",
      " 'augmented reality features. AR can be computationally intensive and',\n",
      " 'depending on the scale of deployment',\n",
      " 'could lead to increased energy consumption.7. **API Management and '\n",
      " 'Integration Services**: The use of API Management suggests that there are '\n",
      " 'numerous integrations with external systems such as insurance companies',\n",
      " 'partners',\n",
      " 'suppliers',\n",
      " 'and service centers. The overhead of managing these integrations and the '\n",
      " 'potential for inefficient data exchange can increase the carbon footprint.8. '\n",
      " '**Development and Monitoring Services**: Azure DevOps and Azure Monitor are '\n",
      " 'part of the shared services. Continuous integration/continuous deployment '\n",
      " '(CI/CD) pipelines in Azure DevOps can lead to frequent builds and '\n",
      " 'deployments',\n",
      " 'which consume resources. Additionally',\n",
      " 'extensive monitoring and logging can also result in additional storage and '\n",
      " 'processing requirements.To mitigate the carbon footprint',\n",
      " 'the architecture could be optimized by:- Implementing efficient data '\n",
      " 'processing and storage strategies',\n",
      " 'such as data deduplication',\n",
      " 'compression',\n",
      " 'and caching.- Using autoscaling and demand-based provisioning to ensure that '\n",
      " 'resources are scaled down when not in use.- Employing edge computing '\n",
      " 'effectively to process data locally and reduce the amount of data '\n",
      " 'transferred to the cloud.- Optimizing real-time analytics to process only '\n",
      " 'the necessary data and reduce the computational load.- Regularly reviewing '\n",
      " 'and optimizing the CI/CD pipelines to minimize unnecessary builds and '\n",
      " 'deployments.- Ensuring that all services are configured to be as '\n",
      " 'energy-efficient as possible',\n",
      " \"including the use of energy-efficient hardware where applicable.It's \"\n",
      " 'important to note that cloud providers like Microsoft Azure are continuously '\n",
      " 'improving their infrastructure to be more energy-efficient and are investing '\n",
      " 'in renewable energy sources',\n",
      " 'which can help reduce the carbon footprint of cloud services']\n"
     ]
    }
   ],
   "source": [
    "pprint(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Based on the provided solution architecture which appears to be a Microsoft '\n",
      " 'Azure-based IoT solution for vehicles here are some recommendations to '\n",
      " \"optimize the architecture for a lower carbon footprint:1. ('Recommendation': \"\n",
      " \"'Implement serverless architectures where possible' 'Justification': \"\n",
      " \"'Serverless services like Azure Functions can scale automatically and only \"\n",
      " 'consume resources when needed reducing idle time and thus energy '\n",
      " \"consumption.')2. ('Recommendation': 'Optimize data flow to reduce data \"\n",
      " \"transfer' 'Justification': 'Minimizing the amount of data that needs to be \"\n",
      " 'sent across the network can reduce energy consumption. This can be achieved '\n",
      " 'by using edge computing (Azure IoT Edge) to process data locally at the '\n",
      " \"service center before sending it to the cloud.')3. ('Recommendation': 'Use \"\n",
      " \"Azure's sustainability dashboard to monitor and optimize resource usage' \"\n",
      " \"'Justification': 'The sustainability dashboard can provide insights into the \"\n",
      " 'carbon footprint of the cloud services used allowing for targeted '\n",
      " \"optimizations.')4. ('Recommendation': 'Consolidate databases to minimize \"\n",
      " \"redundancy' 'Justification': 'Using multiple databases (Azure Cosmos DB \"\n",
      " 'Azure SQL) can lead to unnecessary duplication of data and increased energy '\n",
      " 'usage. Consolidating data into fewer databases can reduce energy '\n",
      " \"consumption.')5. ('Recommendation': 'Enable auto-scaling and shut down \"\n",
      " \"unused resources' 'Justification': 'Auto-scaling ensures that resources are \"\n",
      " 'used efficiently scaling up during high demand and scaling down during low '\n",
      " \"demand. Shutting down unused resources can also save energy.')6. \"\n",
      " \"('Recommendation': 'Optimize Azure Stream Analytics' 'Justification': \"\n",
      " \"'Stream Analytics jobs can be optimized to run more efficiently processing \"\n",
      " \"data in real-time and reducing the need for large-scale data movement.')7. \"\n",
      " \"('Recommendation': 'Use energy-efficient hardware for IoT devices and \"\n",
      " \"service centers' 'Justification': 'Selecting hardware that is designed for \"\n",
      " 'energy efficiency can significantly reduce the overall carbon footprint of '\n",
      " \"the IoT solution.')8. ('Recommendation': 'Evaluate the necessity of \"\n",
      " \"high-performance components' 'Justification': 'Components like Azure Synapse \"\n",
      " 'Analytics may provide more computing power than necessary for certain '\n",
      " 'workloads. Assessing and scaling these services appropriately can reduce '\n",
      " \"energy consumption.')9. ('Recommendation': 'Implement AI-driven demand \"\n",
      " \"forecasting' 'Justification': 'Using AI to predict usage patterns can help \"\n",
      " 'in optimizing resource allocation and reducing waste thereby lowering the '\n",
      " \"carbon footprint.')10. ('Recommendation': 'Adopt a green cloud provider or \"\n",
      " \"region' 'Justification': 'Choosing a cloud region or provider that uses \"\n",
      " 'renewable energy sources can significantly reduce the carbon footprint of '\n",
      " \"the cloud infrastructure.')These recommendations are based on general best \"\n",
      " 'practices for cloud architecture with a focus on sustainability and may need '\n",
      " 'to be adapted to the specific use case and operational requirements of the '\n",
      " 'solution')\n"
     ]
    }
   ],
   "source": [
    "sentences = \"\"\n",
    "for sentence in recommendations:\n",
    "    sentences = sentences + \" \" + sentence#.replace(\":\", \"\\n\").replace(\"(\", \"\").replace(\")\", \"\\n\").replace(\"'\", \"\")\n",
    "pprint(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_promptx(service: str) -> list[BaseMessage]:\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are a world-class Azure cloud expert.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \n",
    "                \"text\": f\"For the Azure service, named: {service}, provide a detailed model / formula of how to compute an estimate of the carbon cloud footprint leveraging the knowledge about the service. Make required assumptions for the input parameters of the model and then provide an estimate of the carbon cloud footprint of the component. Ensure you clearly describe the model parameters, the assumptions on their values, the formula(s), and the computation of the estimate using the formula(s). The parameters of the model / formula must include datacenter PUE and carbon intensity among others. The output must be organized in only and only the following 'Description of model', 'Model Parameters', 'Assumptions', 'Formulas', 'Computation', and 'Conclusion'. The output must be in json format to allow for digital processing\",\n",
    "                },\n",
    "            ]\n",
    "        )]\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def get_model_footprintx(components):\n",
    "    llm = ChatOpenAI(temperature=0.3, model=\"gpt-4-turbo-preview\", max_tokens=3000, )\n",
    "    chain = RunnableLambda(get_prompt) |  llm\n",
    "\n",
    "    outputs = []\n",
    "    for component in components:\n",
    "        print(component)\n",
    "        output = chain.invoke({'service':component})\n",
    "        outputs.append(output)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Compute Engine']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components = ['Azure Sphere', 'IoT Hub', 'Azure Sphere Security Service', 'Azure Stream Analytics', 'Azure Cosmos DB', 'Azure SQL', 'Azure Synapse Analytics', 'Web and mobile apps', 'Power Platform and BI apps', 'API Management', 'Azure IoT Edge', 'Azure Defender for IoT', 'Azure DevOps', 'Azure Monitor', 'Azure Key Vault', 'Azure Active Directory', 'HoloLens']\n",
    "components = ['Cloud Pub/Sub', 'Cloud Dataflow', 'Cloud Storage', 'Cloud Datastore', 'Cloud Bigtable', 'BigQuery', 'Cloud Dataproc', 'Cloud Datalab', 'App Engine', 'Container Engine', 'Compute Engine']\n",
    "print(\"------------------------------------------------------\")\n",
    "test_component = [components[len(components)-1]]\n",
    "test_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'System: You are a world-class public and private cloud expert.\\nHuman: [{\\'type\\': \\'text\\', \\'text\\': \\'For the cloud service, named: Azure Key Vault, provide a detailed model of how to compute an estimate of the carbon cloud footprint (in kg CO2 per month) leveraging the knowledge about the service. Follow the steps provided below to generate an output in json:\\\\nStep 0: Think about a detailed model for computation of the carbon footprint of the Azure Key Vault. You are not bound by the the examples but here are some example questions to consider: does the service have transactions; does it have to receive data, process data, and return data in these transactions; will there be significant energy consumption in data storage; will the service be running in high availability mode and thus having a higher level of energy consumption; think about the co2_emission_factor relevant in the model; etc etc.\\\\nStep 1: Identify all the input parameters that will be used for the detailed model thought in Step 0. Ensure that the names are concisely defined. Note there will be only one output parameter which is \"carbon_footprint\" which will be the carbon footprint of the service. A parameter is to be considered only if in the subsequent steps it is used in constructing the formula.\\\\nStep 2: Define a formula that would use the parameters in the Step 1. The names of the parameters in the formula must be the ones defined in Step 1.\\\\nStep 3: Make your own required assumptions for the parameters of Step 1 and plug them in the formula of Step 2.\\\\nStep 4: Generate a json as output, with the json containing and only containing the following keys in the order specified below:\\\\n        \"Description\": will describe the detailed model for the Azure Key Vault thought in Step 0,\\\\n        \"Model Parameters\": will be an object containing each of the parameters (in Step 1) as keys and their corresponding values as their descriptions, including the output parameter \\\\\\'carbon_footprint\\\\\\',\\\\n        \"Units\": will be the units for each of the parameters defined under \\\\\\'Model Parameters\\\\\\' - set the value as \\\\\\'ratio\\\\\\' if the parameter is a ratio; if a transaction-like parameter is included in Model Parameters then ensure that the unit is a rate, for example, \\\\\\'transactions per month\\\\\\',\\\\n        \"Formula\": will be an object containing the formula of the Step 2, and in fact will have the starting word as \\\\\\'carbon_footprint\\\\\\',\\\\n        \"Assumptions\": will be an object containing the assumption made in Step 3, and,\\\\n        \"Carbon Footprint\": will be an object containing the computation of the formula in Step 2 based on the assumptions in Step 3. Show the final computed value as \\\\\\'value\\\\\\', and as well as show how it was computed based on the formula as \\\\\\'computation\\\\\\'.\\\\n\\\\nNotes: \\\\n- Provide a valid json in Step 4 above.\\\\n- Ensure that if a parameter is included under \\\\\\'Model Parameters\\\\\\' then it is also used in the formula defined under \\\\\\'Formula\\\\\\'\\\\n- Ensure that units on both sides of the formula under \\\\\\'Formula\\\\\\' is consistent\\\\n- Provide only values as part of the Assumptions and do not add the units along with the values\\'}]'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prompt(\"Azure Key Vault\").format(service=\"Azure Key Vault\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_human_message():\n",
    "    with open(\"prompts/human_message_for_model_generator.txt\", \"r\") as f:\n",
    "        human_message = f.read()\n",
    "    return human_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For the cloud service, named: Azure Key Vault, provide a detailed model of how to compute an estimate of the carbon cloud footprint (in kg CO2 per month) leveraging the knowledge about the service. Follow the steps provided below to generate an output in json:\\nStep 0: Think about a detailed model for computation of the carbon footprint of the Azure Key Vault. You are not bound by the the examples but here are some example questions to consider: does the service have transactions; does it have to receive data, process data, and return data in these transactions; will there be significant energy consumption in data storage; will the service be running in high availability mode and thus having a higher level of energy consumption; think about the co2_emission_factor relevant in the model; etc etc.\\nStep 1: Identify all the input parameters that will be used for the detailed model thought in Step 0. Ensure that the names are concisely defined. Note there will be only one output parameter which is \"carbon_footprint\" which will be the carbon footprint of the service. A parameter is to be considered only if in the subsequent steps it is used in constructing the formula.\\nStep 2: Define a formula that would use the parameters in the Step 1. The names of the parameters in the formula must be the ones defined in Step 1.\\nStep 3: Make your own required assumptions for the parameters of Step 1 and plug them in the formula of Step 2.\\nStep 4: Generate a json as output, with the json containing and only containing the following keys in the order specified below:\\n        \"Description\": will describe the detailed model for the Azure Key Vault thought in Step 0,\\n        \"Model Parameters\": will be an object containing each of the parameters (in Step 1) as keys and their corresponding values as their descriptions, including the output parameter \\'carbon_footprint\\',\\n        \"Units\": will be the units for each of the parameters defined under \\'Model Parameters\\' - set the value as \\'ratio\\' if the parameter is a ratio; if a transaction-like parameter is included in Model Parameters then ensure that the unit is a rate, for example, \\'transactions per month\\',\\n        \"Formula\": will be an object containing the formula of the Step 2, and in fact will have the starting word as \\'carbon_footprint\\',\\n        \"Assumptions\": will be an object containing the assumption made in Step 3, and,\\n        \"Carbon Footprint\": will be an object containing the computation of the formula in Step 2 based on the assumptions in Step 3. Show the final computed value as \\'value\\', and as well as show how it was computed based on the formula as \\'computation\\'.\\n\\nNotes: \\n- Provide a valid json in Step 4 above.\\n- Ensure that if a parameter is included under \\'Model Parameters\\' then it is also used in the formula defined under \\'Formula\\'\\n- Ensure that units on both sides of the formula under \\'Formula\\' is consistent\\n- Provide only values as part of the Assumptions and do not add the units along with the values'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = get_human_message().format(service='Azure Key Vault')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Engine\n"
     ]
    }
   ],
   "source": [
    "outputs = get_model_footprint(test_component)\n",
    "#print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"Description\": \"The model for computing the carbon footprint of the Compute Engine service considers the energy consumption of the virtual machines (VMs) based on their size (CPU and memory), the number of hours they run, the energy source of the data center, and the co2 emission factor of the energy source. It also takes into account the data transfer in and out of the VMs, assuming that data transfer has a carbon footprint due to the energy used in transmitting data over the network.\",\\n  \"Model Parameters\": {\\n    \"vm_hours\": \"Total number of hours all VMs run in a month\",\\n    \"cpu_cores\": \"Number of CPU cores per VM\",\\n    \"memory_gb\": \"Amount of memory in GB per VM\",\\n    \"data_transfer_gb\": \"Total amount of data transferred in and out of the VMs in GB\",\\n    \"energy_efficiency_ratio\": \"Energy efficiency of the data center, represented as a ratio\",\\n    \"co2_emission_factor\": \"CO2 emission factor of the energy source, in kg CO2 per kWh\",\\n    \"carbon_footprint\": \"The carbon footprint of the Compute Engine service, in kg CO2 per month\"\\n  },\\n  \"Units\": {\\n    \"vm_hours\": \"hours\",\\n    \"cpu_cores\": \"cores\",\\n    \"memory_gb\": \"GB\",\\n    \"data_transfer_gb\": \"GB\",\\n    \"energy_efficiency_ratio\": \"ratio\",\\n    \"co2_emission_factor\": \"kg CO2 per kWh\",\\n    \"carbon_footprint\": \"kg CO2 per month\"\\n  },\\n  \"Formula\": {\\n    \"carbon_footprint\": \"(vm_hours * (cpu_cores * 0.75 + memory_gb * 0.002) * energy_efficiency_ratio + data_transfer_gb * 0.01) * co2_emission_factor\"\\n  },\\n  \"Assumptions\": {\\n    \"vm_hours\": 720,\\n    \"cpu_cores\": 8,\\n    \"memory_gb\": 32,\\n    \"data_transfer_gb\": 1000,\\n    \"energy_efficiency_ratio\": 1.1,\\n    \"co2_emission_factor\": 0.4\\n  },\\n  \"Carbon Footprint\": {\\n    \"value\": 205.92,\\n    \"computation\": \"(720 * (8 * 0.75 + 32 * 0.002) * 1.1 + 1000 * 0.01) * 0.4\"\\n  }\\n}\\n```'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findnth(haystack, needle, n):\n",
    "    parts= haystack.split(needle, n+1)\n",
    "    if len(parts)<=n+1:\n",
    "        return -1\n",
    "    return len(haystack)-len(parts[-1])-len(needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original string is : ```json\n",
      "{\n",
      "  \"Description\": \"The model for computing the carbon footprint of Azure DevOps considers the energy consumption of server operations involved in continuous integration/continuous deployment (CI/CD) pipelines, data storage, and data transfer activities. It factors in the number of builds, storage used, data transferred, and the co2 emission factor of the data centers.\",\n",
      "  \"Model Parameters\": {\n",
      "    \"builds_per_month\": \"Number of CI/CD pipeline executions per month\",\n",
      "    \"average_build_energy\": \"Average energy consumed per build\",\n",
      "    \"storage_gb\": \"Amount of data storage used in GB\",\n",
      "    \"storage_energy_per_gb\": \"Energy consumed per GB of stored data per month\",\n",
      "    \"data_transfer_gb\": \"Amount of data transferred in GB\",\n",
      "    \"data_transfer_energy_per_gb\": \"Energy consumed per GB of data transferred\",\n",
      "    \"co2_emission_factor\": \"CO2 emission factor of the data center\",\n",
      "    \"carbon_footprint\": \"Total carbon footprint of the Azure DevOps service in kg CO2 per month\"\n",
      "  },\n",
      "  \"Units\": {\n",
      "    \"builds_per_month\": \"builds per month\",\n",
      "    \"average_build_energy\": \"kWh per build\",\n",
      "    \"storage_gb\": \"GB\",\n",
      "    \"storage_energy_per_gb\": \"kWh per GB per month\",\n",
      "    \"data_transfer_gb\": \"GB\",\n",
      "    \"data_transfer_energy_per_gb\": \"kWh per GB\",\n",
      "    \"co2_emission_factor\": \"kg CO2 per kWh\",\n",
      "    \"carbon_footprint\": \"kg CO2 per month\"\n",
      "  },\n",
      "  \"Formula\": {\n",
      "    \"carbon_footprint\": \"(builds_per_month * average_build_energy + storage_gb * storage_energy_per_gb + data_transfer_gb * data_transfer_energy_per_gb) * co2_emission_factor\"\n",
      "  },\n",
      "  \"Assumptions\": {\n",
      "    \"builds_per_month\": 1000,\n",
      "    \"average_build_energy\": 0.015,\n",
      "    \"storage_gb\": 500,\n",
      "    \"storage_energy_per_gb\": 0.002,\n",
      "    \"data_transfer_gb\": 1000,\n",
      "    \"data_transfer_energy_per_gb\": 0.001,\n",
      "    \"co2_emission_factor\": 0.4\n",
      "  },\n",
      "  \"Carbon Footprint\": {\n",
      "    \"value\": 22,\n",
      "    \"computation\": \"(1000 * 0.015 + 500 * 0.002 + 1000 * 0.001) * 0.4\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "0\n",
      "1907\n",
      "The extracted string : {\n",
      "  \"Description\": \"The model for computing the carbon footprint of Azure DevOps considers the energy consumption of server operations involved in continuous integration/continuous deployment (CI/CD) pipelines, data storage, and data transfer activities. It factors in the number of builds, storage used, data transferred, and the co2 emission factor of the data centers.\",\n",
      "  \"Model Parameters\": {\n",
      "    \"builds_per_month\": \"Number of CI/CD pipeline executions per month\",\n",
      "    \"average_build_energy\": \"Average energy consumed per build\",\n",
      "    \"storage_gb\": \"Amount of data storage used in GB\",\n",
      "    \"storage_energy_per_gb\": \"Energy consumed per GB of stored data per month\",\n",
      "    \"data_transfer_gb\": \"Amount of data transferred in GB\",\n",
      "    \"data_transfer_energy_per_gb\": \"Energy consumed per GB of data transferred\",\n",
      "    \"co2_emission_factor\": \"CO2 emission factor of the data center\",\n",
      "    \"carbon_footprint\": \"Total carbon footprint of the Azure DevOps service in kg CO2 per month\"\n",
      "  },\n",
      "  \"Units\": {\n",
      "    \"builds_per_month\": \"builds per month\",\n",
      "    \"average_build_energy\": \"kWh per build\",\n",
      "    \"storage_gb\": \"GB\",\n",
      "    \"storage_energy_per_gb\": \"kWh per GB per month\",\n",
      "    \"data_transfer_gb\": \"GB\",\n",
      "    \"data_transfer_energy_per_gb\": \"kWh per GB\",\n",
      "    \"co2_emission_factor\": \"kg CO2 per kWh\",\n",
      "    \"carbon_footprint\": \"kg CO2 per month\"\n",
      "  },\n",
      "  \"Formula\": {\n",
      "    \"carbon_footprint\": \"(builds_per_month * average_build_energy + storage_gb * storage_energy_per_gb + data_transfer_gb * data_transfer_energy_per_gb) * co2_emission_factor\"\n",
      "  },\n",
      "  \"Assumptions\": {\n",
      "    \"builds_per_month\": 1000,\n",
      "    \"average_build_energy\": 0.015,\n",
      "    \"storage_gb\": 500,\n",
      "    \"storage_energy_per_gb\": 0.002,\n",
      "    \"data_transfer_gb\": 1000,\n",
      "    \"data_transfer_energy_per_gb\": 0.001,\n",
      "    \"co2_emission_factor\": 0.4\n",
      "  },\n",
      "  \"Carbon Footprint\": {\n",
      "    \"value\": 22,\n",
      "    \"computation\": \"(1000 * 0.015 + 500 * 0.002 + 1000 * 0.001) * 0.4\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_str = outputs[0].content\n",
    " \n",
    "# printing original string\n",
    "print(\"The original string is : \" + str(test_str))\n",
    " \n",
    "# initializing substrings\n",
    "sub1 = \"```json\"\n",
    "sub2 = \"```\"\n",
    " \n",
    "# getting index of substrings\n",
    "idx1 = test_str.find(sub1)\n",
    "print(idx1)\n",
    "idx2 = test_str.find(sub2)\n",
    "idx2 = test_str.replace(sub2, 'XXX', 1).find(sub2)\n",
    "print(idx2)\n",
    " \n",
    "# length of substring 1 is added to\n",
    "# get string from next character\n",
    "res = test_str[idx1 + len(sub1) + 1: idx2]\n",
    " \n",
    "# printing result\n",
    "print(\"The extracted string : \" + res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_formula(parameters, formula):\n",
    "    for parameter in parameters.keys():\n",
    "        formula = formula.replace(parameter, str(parameters[parameter]))\n",
    "    print(formula)\n",
    "    value = eval(formula)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(builds_per_month * average_build_energy + storage_gb * storage_energy_per_gb + data_transfer_gb * data_transfer_energy_per_gb) * co2_emission_factor\n",
      "(1000 * 0.015 + 500 * 0.002 + 1000 * 0.001) * 0.4\n",
      "6.800000000000001\n",
      "6.800000000000001\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "x = json.loads(res)\n",
    "print(x['Formula']['carbon_footprint'])\n",
    "# replace a substring with another string\n",
    "calculate_formula(x['Assumptions'], x['Formula']['carbon_footprint'])\n",
    "print(eval(x['Carbon Footprint']['computation']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sust_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
